{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of CIFAR-10\n",
    "In this notebook, I will perform an exploratory data analysis of the CIFAR-10 dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The objectives of my EDA are to discover the question for the following questions:\n",
    "- What is the size of the dataset?\n",
    "- How many classes are in the dataset?\n",
    "- What is the resolution of images in the dataset?\n",
    "- How many images are there per class?\n",
    "- What are the statistics of the images per class? (e.g. mean pixel value)\n",
    "- What are the ground truth KID, FID, and IS scores of the data?\n",
    "- What do images of each class look like in the dataset?\n",
    "- What is the diversity of images in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /root/.ssh\n",
    "with open(\"/root/.ssh/id_rsa\", mode=\"w\") as fp: # Repository Deploy Key\n",
    "    fp.write(\"\"\"\n",
    "-----BEGIN RSA PRIVATE KEY-----\n",
    "MIIJKgIBAAKCAgEAt4IzVm1w9r7xKuS+zYuBb6UNB2NFHQBaRbhih7+HBK+yNSbz\n",
    "lGu9P/sWbFarsY68zKCISb8+K+hulP0ay9OdnCLat9z96eOZ0gX6Iqsh6+szfNvm\n",
    "8m1SJeXc7C6UGmyNIpr33TUpf56y28UFa656rIjff1w20SRKjL2rgu8rx+lxiASL\n",
    "+hXiZi2t1PA6oLD3puD9TOwN85Ct5mutmTjBYQKbmk04Sp8jE9DqloJPpkCJHVh6\n",
    "cJ0bzyVCx4njzdoQeWwPtVa67wyHIXDqH1xZBAkAqt2WAx4npLGgTotPSUaFkDLw\n",
    "co6SnpOLx8ZGrpggX1k2Oh7FOH75nZXHKjrfWtX5pbkw8bxYmNLTErq/t19ULBQi\n",
    "dVyv406ARf1rDOUFoMfsOsc1pd/wf66mcZUn3s3ogI6it5zGrpzCpfrlxHgJQ/Uh\n",
    "gvyWA88J6BRVgMA5cUS4gb/OEmuHvdM9CRY6HELAS35tS85zcRQXipYqngx/dgaV\n",
    "GhHHIWZh1bOkbn1dRV3xQau6KxYOyLI/i+eBFJA3jxvDKlRMVfy1DMSn0DffFlFt\n",
    "ApOAqOccYo124vUthsiWJ9qExdCJ36+tAHpFelfyjAygJMWCZhaWprxvY9VG/lcR\n",
    "6vjNtjaUySWx3l4GTadmbSwARK9gl5Xgbp0qojx1FMpsFcnCsz3y8yB7TYECAwEA\n",
    "AQKCAgBVmHSrxqafYVcKg+H/7Cd21QzrukEdkvGIfcXvvcWTyQQdyMprG4oN0ueV\n",
    "pyO00Xh9FhAcHgk439Tcx+Z81ns4vgU5J+qD8zbngQQ4sYxEB9RfVA84WwerR7mx\n",
    "rNRGMwXt80zUMJznuzWATzkFDkCIQ9vEA1ZKXVwso7fhff/04o2jPUOxZg3RTVM8\n",
    "9MTT+Ve6zk04WQ704jJLPUSfKJsCzf2YjpZIMExjTNpvU98lFAsg1gleh9nV2HJ6\n",
    "snXAqgtvJ5l4IzlUkYpibdG2yRN4T16xVGRJlgI1zuiQWmikLDHWnfwL4za+ouHb\n",
    "UD/d5nWLJAioOXwSqx9xgtCAgS92211ydmKWmsdThHdRDN63ncFPNg7I3ZVdRKOK\n",
    "bdAMev6sP3CXnWO7aRO0sGT4wg7tGbnyE53I4RJXck1aZZGSyOvswucCxEQsnbSP\n",
    "Hr78/kc+5+DJX8pbc0NuLAspkUVoSU75Idrv5B+2UQSb1ZXspfp923s0voRw0sJ8\n",
    "ydOg1n173QOwKnAE++tXQrdPZyU2cHkuvg426snCjlpbogfmmlj8cGGb8EOZcdJv\n",
    "I3r+w2V+9bC2Z7O4OJhe2HlwM0N6F+KBnyJHsxbdP08OqZYzVMiDmg5Rfbkwf8W9\n",
    "arkt9+pAWSix0nkp7qNgD+qkjfrtOxIX//mFbIBWhhq1gSby5QKCAQEA63P0DsuC\n",
    "APhI0/GeSFJ8FXYtVFrX8/DJjOH441VEaQQMlAub6KnlhsOo0nS10A5GqV9/EeZ7\n",
    "ss2w22JwIh+Wk6PtxPU7lMEQRy1eV0GUrQdrE8StlLs36zszMswMafnm4yA4ki6g\n",
    "Lr3BR6Ps38TzLba6mctOFt9T8wV6+/YB2PFi3r5tmX0zYNQi6mbTFnlDv/dzaFOG\n",
    "fT823OuOzuwVvgu90651PutVfPrNhUTTykuGyDee5kkn21HQeguoLDWEIfeV+ujH\n",
    "l/AAT7rpNmxtSl0m+iwYsbKDbX28DCGnWXgeMuFgMUblRvKumChbno81JkJIOOwV\n",
    "+DcWryqTLp17VwKCAQEAx4XN5+PGMg9na7vZW6zU8r92RFKsjjhueygtpxdDUjdV\n",
    "MSYPu4mgO9ab62nf9LQJE2JCN6e8zHWEAooaIt83TzCa6SaYbTEnzin2M9gSYtW6\n",
    "MQ429zq49MOdZfwMfRgfnFAnA8KDIfYqqcPcmnQWHWhNGXyS3CccYw+2+gmRHLoM\n",
    "ohcoVZne6VuMqkEzf8SDaR8k9gwVjqxVqpQN8p81PE00a02k+QDwyNsrcnM19plB\n",
    "kntb9FLuqQf+lmDhe0/9fDqcjIEDz4eonLlFaTrFegGybTQcKD+3uyC0k9njUFwJ\n",
    "Y77I3kJiaoDuXXVxWETS3KvaE2rmjXAEcrN5rkfO5wKCAQEAl+41kQputBOCYwjp\n",
    "Ov/Gw86DB4irCuTYGYmDIaZWw3DycOFg1Gw1CJXerRbUbxGXNRnDFBjmvwUNVzMY\n",
    "6lv5vQEtn0cjECTYTSWQV7ugpVpBFPt3ip6YQbjsm52hcQzpmKuk9WcSw7Z8Lq8v\n",
    "XWFoDZp4pF7U39tx/0INDuK6ZHO2ecblUALDEXsxoJGDKmBLgGa7WJl1EgKlcz6o\n",
    "4wriKMTI0/wh+dy/SCtKTPGRvFqp+S4y4aRZDKOpY+d7uDM8NPLfG43zpS4f9VLF\n",
    "w/GJQFAFo66qrJdlSVS18BoTM59X1Tsq6AE4V2SnltWL8S+1ex+QHPLyZj2d7KAL\n",
    "YywJdwKCAQEApWUG3j6T0nWwfr82nGc2E5ChgluiTTb8Zr1Ustl25hWWWmq5yfV5\n",
    "TYFGuSyICTqg91+Rkr9Ko5aa+tvudI/jMpMRJ0rmOkXwQFfKjwmDnEid0wJ8kA8u\n",
    "uT/bH2qEE8LGmXZcESLSP3nnvdjt619l4bTPjNwWhccqIfgp7zW1BEI6LLfTqLon\n",
    "7fwFLDFmdni5ko/NvOUhjabQUNnwgfp2T+mUFYtEwWGFOItuha55wlUi5UG7ZVrG\n",
    "GnrVEWV4JReXAr83fMWKGiPToy92GZgtkUkM1rfGy5qePNIMvy903u2cnwHNU2lm\n",
    "WfFNJ04uykQrI+CVo1kPi5mbJlYe/VjrawKCAQEA5Pmjb8/MdAUEkb3zAD7GJIKC\n",
    "HnUAA4mwk8xVdsGN6xvUL8RYgi+VjSKvzNsUln5sPXdtZbP//gQOF7KgLPFFe+mf\n",
    "Xok7fGSTQ1DgVWEErFynAYxu+Uu4xtjRbPyCXjyoHianXkn3QDf1ggpF+y2R0Ivu\n",
    "oyxsDvMArFalbmK4q/+Q6/z/DtnirfjUnxiYEPEBZtP3Gz74KQK/AhForVlCiSz6\n",
    "MbDp30cxPy/8/pimJ9xUR6re9Xuw/EFWp0ifHXv6IGNOd8UQGejyI82KnJZPNTde\n",
    "tHO70d3zFdhrpJO63Elrw6c9bxeZrcJTT1e3wFpX2z1aE4dybdNqrI/IbzcdVA==\n",
    "-----END RSA PRIVATE KEY-----\n",
    "\"\"\")\n",
    "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
    "! chmod go-rwx /root/.ssh/id_rsa\n",
    "! git clone git@github.com:Tien-Cheng/dele-generative-adversarial-networks.git\n",
    "%cd /content/dele-generative-adversarial-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U torch-fidelity wandb pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_fidelity\n",
    "from utils.visualize import visualize\n",
    "from data.dataset import CIFAR10DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### CIFAR-10\n",
    "\n",
    "CIFAR-10 is a labelled subset of the 80 million tiny images dataset. It consists of 60000 32x32 color images in 10 classes.\n",
    "\n",
    "- They are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\n",
    "There are 6000 images per class. CIFAR-10 splits data into 50000 training images, and 10000 test images. It is a common benchmark dataset, used to evaluate computer vision models. It is also commonly used as a benchmark for GAN training, as GAN training typically takes a long time, and so a smaller dataset like CIFAR with a lower resolution is easier to train, allowing GAN models to be more easily evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CIFAR10DataModule(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(dm.cifar_train)\n",
    "test_len = len(dm.cifar_test)\n",
    "\n",
    "print(f\"The size of the training split is {train_len}, the size of the test split is {test_len}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
