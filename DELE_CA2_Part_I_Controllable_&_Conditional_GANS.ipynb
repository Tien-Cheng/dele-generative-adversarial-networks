{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tien-Cheng/dele-generative-adversarial-networks/blob/main/DELE_CA2_Part_I_Controllable_%26_Conditional_GANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYWgFv3Lw7Um"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "> How can I create a GAN model that allows me to control the generated output, so as to enable me to express my creativity>\n",
        "\n",
        "## What I Want to Do\n",
        "\n",
        "- Create a Conditional GAN that:\n",
        "  - Achieves a good FID and KID score (i.e. good image quality)\n",
        "  - Is able to successfully generate images based on class\n",
        "  - Potentially allows me to control the features of the image (e.g. color)\n",
        "\n",
        "## How will I achieve it?\n",
        "\n",
        "- I will try various network architectures\n",
        "\n",
        "  - DCGAN\n",
        "  - SNGAN\n",
        "  - StyleGAN2\n",
        "\n",
        "- To improve the quality of images, I apply the following techniques\n",
        "  - FreezeD (Transfer Learning)\n",
        "  - Truncation Trick\n",
        "  - Differentiable Augmentation\n",
        "  - Hinge Loss\n",
        "  - Two Time Update Rule\n",
        "  - Skip Connections from Noise to Generator (which could allow for GANSpace edits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff5jtmM4-S6V"
      },
      "source": [
        "# Google Colab Setup\n",
        "\n",
        "Due to the heavy computational requirements for training a GAN, Google Colab is used as a compute platform. The dataset and utilty functions have been stored on a GitHub repository, and so we need to clone the Git repo. In addition, some additional libraries have to be installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1nKt9XhE_lL",
        "outputId": "1507ed6e-79f2-404b-c7b2-d364d9dba314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# github.com:22 SSH-2.0-babeld-e47cd09f\n",
            "chmod: cannot access '/root/.ssh/rsa': No such file or directory\n",
            "Cloning into 'dele-generative-adversarial-networks'...\n",
            "Warning: Permanently added the ED25519 host key for IP address '192.30.255.112' to the list of known hosts.\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 20 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (26/26), 7.52 KiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/dele-generative-adversarial-networks\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p /root/.ssh\n",
        "with open(\"/root/.ssh/id_rsa\", mode=\"w\") as fp: # Repository Deploy Key\n",
        "    fp.write(\"\"\"\n",
        "-----BEGIN RSA PRIVATE KEY-----\n",
        "MIIJKgIBAAKCAgEAt4IzVm1w9r7xKuS+zYuBb6UNB2NFHQBaRbhih7+HBK+yNSbz\n",
        "lGu9P/sWbFarsY68zKCISb8+K+hulP0ay9OdnCLat9z96eOZ0gX6Iqsh6+szfNvm\n",
        "8m1SJeXc7C6UGmyNIpr33TUpf56y28UFa656rIjff1w20SRKjL2rgu8rx+lxiASL\n",
        "+hXiZi2t1PA6oLD3puD9TOwN85Ct5mutmTjBYQKbmk04Sp8jE9DqloJPpkCJHVh6\n",
        "cJ0bzyVCx4njzdoQeWwPtVa67wyHIXDqH1xZBAkAqt2WAx4npLGgTotPSUaFkDLw\n",
        "co6SnpOLx8ZGrpggX1k2Oh7FOH75nZXHKjrfWtX5pbkw8bxYmNLTErq/t19ULBQi\n",
        "dVyv406ARf1rDOUFoMfsOsc1pd/wf66mcZUn3s3ogI6it5zGrpzCpfrlxHgJQ/Uh\n",
        "gvyWA88J6BRVgMA5cUS4gb/OEmuHvdM9CRY6HELAS35tS85zcRQXipYqngx/dgaV\n",
        "GhHHIWZh1bOkbn1dRV3xQau6KxYOyLI/i+eBFJA3jxvDKlRMVfy1DMSn0DffFlFt\n",
        "ApOAqOccYo124vUthsiWJ9qExdCJ36+tAHpFelfyjAygJMWCZhaWprxvY9VG/lcR\n",
        "6vjNtjaUySWx3l4GTadmbSwARK9gl5Xgbp0qojx1FMpsFcnCsz3y8yB7TYECAwEA\n",
        "AQKCAgBVmHSrxqafYVcKg+H/7Cd21QzrukEdkvGIfcXvvcWTyQQdyMprG4oN0ueV\n",
        "pyO00Xh9FhAcHgk439Tcx+Z81ns4vgU5J+qD8zbngQQ4sYxEB9RfVA84WwerR7mx\n",
        "rNRGMwXt80zUMJznuzWATzkFDkCIQ9vEA1ZKXVwso7fhff/04o2jPUOxZg3RTVM8\n",
        "9MTT+Ve6zk04WQ704jJLPUSfKJsCzf2YjpZIMExjTNpvU98lFAsg1gleh9nV2HJ6\n",
        "snXAqgtvJ5l4IzlUkYpibdG2yRN4T16xVGRJlgI1zuiQWmikLDHWnfwL4za+ouHb\n",
        "UD/d5nWLJAioOXwSqx9xgtCAgS92211ydmKWmsdThHdRDN63ncFPNg7I3ZVdRKOK\n",
        "bdAMev6sP3CXnWO7aRO0sGT4wg7tGbnyE53I4RJXck1aZZGSyOvswucCxEQsnbSP\n",
        "Hr78/kc+5+DJX8pbc0NuLAspkUVoSU75Idrv5B+2UQSb1ZXspfp923s0voRw0sJ8\n",
        "ydOg1n173QOwKnAE++tXQrdPZyU2cHkuvg426snCjlpbogfmmlj8cGGb8EOZcdJv\n",
        "I3r+w2V+9bC2Z7O4OJhe2HlwM0N6F+KBnyJHsxbdP08OqZYzVMiDmg5Rfbkwf8W9\n",
        "arkt9+pAWSix0nkp7qNgD+qkjfrtOxIX//mFbIBWhhq1gSby5QKCAQEA63P0DsuC\n",
        "APhI0/GeSFJ8FXYtVFrX8/DJjOH441VEaQQMlAub6KnlhsOo0nS10A5GqV9/EeZ7\n",
        "ss2w22JwIh+Wk6PtxPU7lMEQRy1eV0GUrQdrE8StlLs36zszMswMafnm4yA4ki6g\n",
        "Lr3BR6Ps38TzLba6mctOFt9T8wV6+/YB2PFi3r5tmX0zYNQi6mbTFnlDv/dzaFOG\n",
        "fT823OuOzuwVvgu90651PutVfPrNhUTTykuGyDee5kkn21HQeguoLDWEIfeV+ujH\n",
        "l/AAT7rpNmxtSl0m+iwYsbKDbX28DCGnWXgeMuFgMUblRvKumChbno81JkJIOOwV\n",
        "+DcWryqTLp17VwKCAQEAx4XN5+PGMg9na7vZW6zU8r92RFKsjjhueygtpxdDUjdV\n",
        "MSYPu4mgO9ab62nf9LQJE2JCN6e8zHWEAooaIt83TzCa6SaYbTEnzin2M9gSYtW6\n",
        "MQ429zq49MOdZfwMfRgfnFAnA8KDIfYqqcPcmnQWHWhNGXyS3CccYw+2+gmRHLoM\n",
        "ohcoVZne6VuMqkEzf8SDaR8k9gwVjqxVqpQN8p81PE00a02k+QDwyNsrcnM19plB\n",
        "kntb9FLuqQf+lmDhe0/9fDqcjIEDz4eonLlFaTrFegGybTQcKD+3uyC0k9njUFwJ\n",
        "Y77I3kJiaoDuXXVxWETS3KvaE2rmjXAEcrN5rkfO5wKCAQEAl+41kQputBOCYwjp\n",
        "Ov/Gw86DB4irCuTYGYmDIaZWw3DycOFg1Gw1CJXerRbUbxGXNRnDFBjmvwUNVzMY\n",
        "6lv5vQEtn0cjECTYTSWQV7ugpVpBFPt3ip6YQbjsm52hcQzpmKuk9WcSw7Z8Lq8v\n",
        "XWFoDZp4pF7U39tx/0INDuK6ZHO2ecblUALDEXsxoJGDKmBLgGa7WJl1EgKlcz6o\n",
        "4wriKMTI0/wh+dy/SCtKTPGRvFqp+S4y4aRZDKOpY+d7uDM8NPLfG43zpS4f9VLF\n",
        "w/GJQFAFo66qrJdlSVS18BoTM59X1Tsq6AE4V2SnltWL8S+1ex+QHPLyZj2d7KAL\n",
        "YywJdwKCAQEApWUG3j6T0nWwfr82nGc2E5ChgluiTTb8Zr1Ustl25hWWWmq5yfV5\n",
        "TYFGuSyICTqg91+Rkr9Ko5aa+tvudI/jMpMRJ0rmOkXwQFfKjwmDnEid0wJ8kA8u\n",
        "uT/bH2qEE8LGmXZcESLSP3nnvdjt619l4bTPjNwWhccqIfgp7zW1BEI6LLfTqLon\n",
        "7fwFLDFmdni5ko/NvOUhjabQUNnwgfp2T+mUFYtEwWGFOItuha55wlUi5UG7ZVrG\n",
        "GnrVEWV4JReXAr83fMWKGiPToy92GZgtkUkM1rfGy5qePNIMvy903u2cnwHNU2lm\n",
        "WfFNJ04uykQrI+CVo1kPi5mbJlYe/VjrawKCAQEA5Pmjb8/MdAUEkb3zAD7GJIKC\n",
        "HnUAA4mwk8xVdsGN6xvUL8RYgi+VjSKvzNsUln5sPXdtZbP//gQOF7KgLPFFe+mf\n",
        "Xok7fGSTQ1DgVWEErFynAYxu+Uu4xtjRbPyCXjyoHianXkn3QDf1ggpF+y2R0Ivu\n",
        "oyxsDvMArFalbmK4q/+Q6/z/DtnirfjUnxiYEPEBZtP3Gz74KQK/AhForVlCiSz6\n",
        "MbDp30cxPy/8/pimJ9xUR6re9Xuw/EFWp0ifHXv6IGNOd8UQGejyI82KnJZPNTde\n",
        "tHO70d3zFdhrpJO63Elrw6c9bxeZrcJTT1e3wFpX2z1aE4dybdNqrI/IbzcdVA==\n",
        "-----END RSA PRIVATE KEY-----\n",
        "\"\"\")\n",
        "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "! chmod go-rwx /root/.ssh/id_rsa\n",
        "! git clone git@github.com:Tien-Cheng/dele-generative-adversarial-networks.git\n",
        "%cd /content/dele-generative-adversarial-networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRBkXblK-YpQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U torchmetrics[image] wandb torch-summary pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w4OzpB6-c_1"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw-0sgET-fKb"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zumKbcFW-cqB",
        "outputId": "c017a963-122d-4adf-de37-4f9bbb186895"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import wandb\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from typing import *\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.optim import Adam\n",
        "from data.dataset import CIFAR10DataModule\n",
        "from torchvision import transforms as T\n",
        "from torchmetrics.image import FID  # Frechet Inception Distance\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelSummary, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from utils.DiffAugment_pytorch import (\n",
        "    DiffAugment,\n",
        ")  # Make use of the official implementation of DiffAugment\n",
        "from utils.visualize import visualize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0RQBSYpS_HQ"
      },
      "source": [
        "### Basic Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gLPRMOsgSW8w",
        "outputId": "cae5707b-9a4a-4e95-f7fa-397a39c719f6"
      },
      "outputs": [],
      "source": [
        "# @title Basic Hyperparameters { run: \"auto\" }\n",
        "DATA_DIR = \"./data\"  # @param {type:\"string\"}\n",
        "BATCH_SIZE = 256  # @param {type:\"integer\"}\n",
        "NUM_WORKERS = 1  # @param {type:\"integer\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu9T96d-_Rnf"
      },
      "source": [
        "## Data Ingestion and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q4fq4ltATFhN",
        "outputId": "a6183af8-1173-4ab6-8f84-884ed1dfbf5f"
      },
      "outputs": [],
      "source": [
        "preprocessing = [T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "P1YteEfJSKQY",
        "outputId": "f6c13f91-f7e7-4237-de35-de50e6c4c2fc"
      },
      "outputs": [],
      "source": [
        "dm = CIFAR10DataModule(\n",
        "    data_dir=DATA_DIR,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    transforms=preprocessing,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag08rZ3W_d3E"
      },
      "source": [
        "# Building a Conditional LSGAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf2aymldARgo"
      },
      "source": [
        "## Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iMQ65GSH_3sf"
      },
      "outputs": [],
      "source": [
        "class LSGANGenerator(nn.Module):\n",
        "    def __init__(\n",
        "        self, latent_dim: int = 100, num_filters: int = 64, num_classes: int = 10\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_filters = num_filters  # Base Number of Filters in Generator Blocks\n",
        "        self.num_classes = num_classes\n",
        "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                latent_dim + self.num_classes, num_filters * 8, 4, 1, 0, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_filters * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(num_filters * 8, num_filters * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(num_filters * 4, num_filters * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(num_filters * 2, num_filters, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(num_filters, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: list = None):\n",
        "        conditional_inputs = torch.cat([x, self.label_embedding(y)], dim=-1)\n",
        "        return self.main(conditional_inputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCRwH4cAATql"
      },
      "source": [
        "## Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pj4rGgeiAVkX"
      },
      "outputs": [],
      "source": [
        "class LSGANDiscriminator(nn.Module):\n",
        "    def __init__(self, num_filters: int = 64, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.num_classes = num_classes\n",
        "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(3, num_filters, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(num_filters, num_filters * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(num_filters * 2, num_filters * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(num_filters * 4, num_filters * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(\n",
        "                num_filters * 8, 1, 4, 1, 0, bias=False\n",
        "            ),  # Apply a 4x4 Convolution to a 4x4 input, resulting in a 1x1 output\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conditional_inputs = torch.cat([x, self.label_embedding(y)], dim=-1)\n",
        "        return self.main(conditional_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NormalizeInverse(T.Normalize):\n",
        "    \"\"\"\n",
        "    Undoes the normalization and returns the reconstructed images in the input domain.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        mean = torch.as_tensor(mean)\n",
        "        std = torch.as_tensor(std)\n",
        "        std_inv = 1 / (std + 1e-7)\n",
        "        mean_inv = -mean * std_inv\n",
        "        super().__init__(mean=mean_inv, std=std_inv)\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return super().__call__(tensor.clone())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRpJbKQRBDTY"
      },
      "source": [
        "## Conditional LSGAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C00_pmG1ENMo"
      },
      "outputs": [],
      "source": [
        "class ConditionalLSGAN(LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 100,\n",
        "        num_classes: int = 10,\n",
        "        g_lr: float = 0.0002,\n",
        "        d_lr: float = 0.0002,\n",
        "        adam_betas: Tuple[float, float] = (0.5, 0.999),\n",
        "        batch_size: int = 64,\n",
        "        validation_size: int = 10000,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.g_lr = g_lr\n",
        "        self.d_lr = d_lr\n",
        "        self.betas = adam_betas\n",
        "        self.batch_size = batch_size\n",
        "        self.validation_size = validation_size  # For FID, minimum number of samples is 10K for accurate result\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.G = LSGANGenerator(\n",
        "            latent_dim=self.latent_dim,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        self.D = LSGANDiscriminator(num_classes=num_classes)\n",
        "\n",
        "        self.G.apply(self._weights_init)\n",
        "        self.D.apply(self._weights_init)\n",
        "\n",
        "        self.adversarial_loss = nn.MSELoss()  # Least Squares Loss\n",
        "\n",
        "        self.fid = FID()\n",
        "        self.unnormalize = NormalizeInverse((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find(\"Conv\") != -1:\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        elif classname.find(\"BatchNorm\") != -1:\n",
        "            torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        return self.G(z, labels)\n",
        "\n",
        "    # def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx,\n",
        "    #                optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n",
        "    #     \"\"\"Only update discriminator every two steps\n",
        "    #     \"\"\"\n",
        "    # # update generator opt every step\n",
        "    #     if optimizer_idx == 0:\n",
        "    #         optimizer.step(closure=optimizer_closure)\n",
        "\n",
        "    #     # update discriminator opt every 2 steps\n",
        "    #     if optimizer_idx == 1:\n",
        "    #         if (batch_idx + 1) % 2 == 0 :\n",
        "    #             optimizer.step(closure=optimizer_closure)\n",
        "    #         else:\n",
        "    #             # call the closure by itself to run `training_step` + `backward` without an optimizer step\n",
        "    #             optimizer_closure()\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        imgs, labels = batch  # Get real images and corresponding labels\n",
        "\n",
        "        # Generate Noise Vector z\n",
        "        z = torch.randn(imgs.shape[0], self.latent_dim)\n",
        "        z = z.type_as(imgs)  # Ensure z runs on the same device as the images\n",
        "        fake_labels = torch.randint(0, self.num_classes, (imgs.shape[0],))\n",
        "        # Train Generator\n",
        "        if optimizer_idx == 0:\n",
        "            # Generate Images\n",
        "            self.fakes = self.forward(z, fake_labels)\n",
        "\n",
        "            # Log Sampled Images\n",
        "            sample_imgs = self.fakes[:9]\n",
        "            sample_labels = fake_labels[:9]\n",
        "            fig = visualize(sample_imgs, sample_labels)\n",
        "            self.logger.log_image(key=\"generated_images\", images=[fig])\n",
        "            # Classify Generated Images with Discriminator\n",
        "            fake_preds = torch.squeeze(self.D(self.fakes, fake_labels))\n",
        "\n",
        "            # We want to penalize the Generator if the Discriminator predicts it as fake\n",
        "            # Hence, set the target as a 1's vector\n",
        "            target = torch.ones(imgs.shape[0]).type_as(imgs)\n",
        "\n",
        "            g_loss = self.adversarial_loss(fake_preds, target)\n",
        "\n",
        "            # self.log(\"train_gen_loss\", g_loss)  # Log Generator Loss\n",
        "            tqdm_dict = {\n",
        "                \"g_loss\": g_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "        # Train Discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Train on Real Data\n",
        "            real_preds = torch.squeeze(self.D(imgs, labels))\n",
        "            target = torch.ones(imgs.shape[0])\n",
        "            d_real_loss = self.adversarial_loss(real_preds, target)\n",
        "\n",
        "            # Train on Generated Images\n",
        "            fake_images = self.forward(z, fake_labels)\n",
        "            target = torch.zeros(imgs.shape[0]).type_as(imgs)\n",
        "            fake_preds = torch.squeeze(self.D(fake_images, fake_labels))\n",
        "            d_fake_loss = self.adversarial_loss(fake_preds, target)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "            # self.log(\"train_discriminator_loss\", d_loss)\n",
        "            tqdm_dict = {\n",
        "                \"d_loss\": d_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Update FID for real Data\n",
        "        \"\"\"\n",
        "        real, _ = batch\n",
        "        # Calculate Metrics for Real Data\n",
        "        real = self.unnormalize(real)\n",
        "        real = (real * 255).type(torch.uint8)\n",
        "        self.fid(\n",
        "            real, real=True\n",
        "        )  # Only log on the end of the epoch as it does not make sense\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        validation_z = torch.randn(self.validation_size, self.latent_dim)\n",
        "        validation_labels = torch.randint(0, self.num_classes, (self.validation_size,))\n",
        "        # Generate Images. A minimum of 10K is recommended for accurate FID\n",
        "        z = validation_z.type_as(\n",
        "            self.G.main[0].weight\n",
        "        )  # Ensure z runs on the same device as the images\n",
        "        fake_labels = validation_labels.type_as(self.G.main[0].weight)\n",
        "        fakes = self.forward(z, fake_labels)  # Display only the first 9 images\n",
        "\n",
        "        # Update FID\n",
        "\n",
        "        self.fid((self.unnormalize(fakes) * 255).astype(torch.uint8), real=False)\n",
        "        self.log(\"FID\", self.fid)\n",
        "\n",
        "        # Generate Outputs\n",
        "        fig = visualize(fakes[:9], fake_labels[:9])\n",
        "\n",
        "        self.logger.log_image(key=\"Validation Images\", images=[fig])\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return fakes  # Send to epoch end callback\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Define the optimizers and schedulers for PyTorch Lightning\n",
        "\n",
        "        :return: A tuple of two lists - a list of optimizers and a list of learning rate schedulers\n",
        "        :rtype: Tuple[List, List]\n",
        "        \"\"\"\n",
        "        opt_G = Adam(\n",
        "            self.G.parameters(), lr=self.g_lr, betas=self.betas\n",
        "        )  # optimizer_idx = 0\n",
        "        opt_D = Adam(\n",
        "            self.D.parameters(), lr=self.d_lr, betas=self.betas\n",
        "        )  # optimizer_idx = 1\n",
        "        return [opt_G, opt_D], []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9LXzAqIAbY0"
      },
      "source": [
        "## Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtiencheng\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n",
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FrechetInceptionDistance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "seed_everything(42)\n",
        "wandb_logger = WandbLogger(project=\"DELE_CA2_GAN\", log_model=\"all\")\n",
        "model = ConditionalLSGAN()\n",
        "trainer = Trainer(\n",
        "    check_val_every_n_epoch=5,\n",
        "    logger=wandb_logger,\n",
        "    max_epochs=5,\n",
        "    callbacks=[\n",
        "        ModelCheckpoint(monitor=\"FID\", mode=\"min\", every_n_epochs=10),\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "  rank_zero_warn(\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | G                 | LSGANGenerator     | 3.7 M \n",
            "1 | G.label_embedding | Embedding          | 100   \n",
            "2 | G.main            | Sequential         | 3.7 M \n",
            "3 | D                 | LSGANDiscriminator | 2.8 M \n",
            "4 | D.label_embedding | Embedding          | 100   \n",
            "5 | D.main            | Sequential         | 2.8 M \n",
            "6 | adversarial_loss  | MSELoss            | 0     \n",
            "7 | fid               | FID                | 23.9 M\n",
            "8 | fid.inception     | NoTrainInceptionV3 | 23.9 M\n",
            "9 | unnormalize       | NormalizeInverse   | 0     \n",
            "---------------------------------------------------------\n",
            "6.4 M     Trainable params\n",
            "23.9 M    Non-trainable params\n",
            "30.3 M    Total params\n",
            "121.101   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a980d1c7c03448b1b36ff11ee8235ce6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, dm)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOI56mbxgkF+EXTRTq++yJk",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "DELE CA2 Part I - Controllable & Conditional GANS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
