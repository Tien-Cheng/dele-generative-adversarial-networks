{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tien-Cheng/dele-generative-adversarial-networks/blob/main/DELE_CA2_Part_I_Controllable_%26_Conditional_GANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYWgFv3Lw7Um"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "> How can I create a GAN model that allows me to control the generated output, so as to enable me to express my creativity>\n",
        "\n",
        "## What I Want to Do\n",
        "\n",
        "- Create a Conditional GAN that:\n",
        "  - Achieves a good FID and KID score (i.e. good image quality)\n",
        "  - Is able to successfully generate images based on class\n",
        "  - Potentially allows me to control the features of the image (e.g. color)\n",
        "\n",
        "## How will I achieve it?\n",
        "\n",
        "- I will try various network architectures\n",
        "\n",
        "  - DCGAN\n",
        "  - SNGAN\n",
        "  - StyleGAN2\n",
        "\n",
        "- To improve the quality of images, I apply the following techniques\n",
        "  - FreezeD (Transfer Learning)\n",
        "  - Truncation Trick\n",
        "  - Differentiable Augmentation\n",
        "  - Hinge Loss\n",
        "  - Two Time Update Rule\n",
        "  - Skip Connections from Noise to Generator (which could allow for GANSpace edits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff5jtmM4-S6V"
      },
      "source": [
        "# Google Colab Setup\n",
        "\n",
        "Due to the heavy computational requirements for training a GAN, Google Colab is used as a compute platform. The dataset and utilty functions have been stored on a GitHub repository, and so we need to clone the Git repo. In addition, some additional libraries have to be installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1nKt9XhE_lL",
        "outputId": "1507ed6e-79f2-404b-c7b2-d364d9dba314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# github.com:22 SSH-2.0-babeld-e47cd09f\n",
            "chmod: cannot access '/root/.ssh/rsa': No such file or directory\n",
            "Cloning into 'dele-generative-adversarial-networks'...\n",
            "Warning: Permanently added the ED25519 host key for IP address '192.30.255.112' to the list of known hosts.\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 20 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (26/26), 7.52 KiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/dele-generative-adversarial-networks\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p /root/.ssh\n",
        "with open(\"/root/.ssh/id_rsa\", mode=\"w\") as fp: # Repository Deploy Key\n",
        "    fp.write(\"\"\"\n",
        "-----BEGIN RSA PRIVATE KEY-----\n",
        "MIIJKgIBAAKCAgEAt4IzVm1w9r7xKuS+zYuBb6UNB2NFHQBaRbhih7+HBK+yNSbz\n",
        "lGu9P/sWbFarsY68zKCISb8+K+hulP0ay9OdnCLat9z96eOZ0gX6Iqsh6+szfNvm\n",
        "8m1SJeXc7C6UGmyNIpr33TUpf56y28UFa656rIjff1w20SRKjL2rgu8rx+lxiASL\n",
        "+hXiZi2t1PA6oLD3puD9TOwN85Ct5mutmTjBYQKbmk04Sp8jE9DqloJPpkCJHVh6\n",
        "cJ0bzyVCx4njzdoQeWwPtVa67wyHIXDqH1xZBAkAqt2WAx4npLGgTotPSUaFkDLw\n",
        "co6SnpOLx8ZGrpggX1k2Oh7FOH75nZXHKjrfWtX5pbkw8bxYmNLTErq/t19ULBQi\n",
        "dVyv406ARf1rDOUFoMfsOsc1pd/wf66mcZUn3s3ogI6it5zGrpzCpfrlxHgJQ/Uh\n",
        "gvyWA88J6BRVgMA5cUS4gb/OEmuHvdM9CRY6HELAS35tS85zcRQXipYqngx/dgaV\n",
        "GhHHIWZh1bOkbn1dRV3xQau6KxYOyLI/i+eBFJA3jxvDKlRMVfy1DMSn0DffFlFt\n",
        "ApOAqOccYo124vUthsiWJ9qExdCJ36+tAHpFelfyjAygJMWCZhaWprxvY9VG/lcR\n",
        "6vjNtjaUySWx3l4GTadmbSwARK9gl5Xgbp0qojx1FMpsFcnCsz3y8yB7TYECAwEA\n",
        "AQKCAgBVmHSrxqafYVcKg+H/7Cd21QzrukEdkvGIfcXvvcWTyQQdyMprG4oN0ueV\n",
        "pyO00Xh9FhAcHgk439Tcx+Z81ns4vgU5J+qD8zbngQQ4sYxEB9RfVA84WwerR7mx\n",
        "rNRGMwXt80zUMJznuzWATzkFDkCIQ9vEA1ZKXVwso7fhff/04o2jPUOxZg3RTVM8\n",
        "9MTT+Ve6zk04WQ704jJLPUSfKJsCzf2YjpZIMExjTNpvU98lFAsg1gleh9nV2HJ6\n",
        "snXAqgtvJ5l4IzlUkYpibdG2yRN4T16xVGRJlgI1zuiQWmikLDHWnfwL4za+ouHb\n",
        "UD/d5nWLJAioOXwSqx9xgtCAgS92211ydmKWmsdThHdRDN63ncFPNg7I3ZVdRKOK\n",
        "bdAMev6sP3CXnWO7aRO0sGT4wg7tGbnyE53I4RJXck1aZZGSyOvswucCxEQsnbSP\n",
        "Hr78/kc+5+DJX8pbc0NuLAspkUVoSU75Idrv5B+2UQSb1ZXspfp923s0voRw0sJ8\n",
        "ydOg1n173QOwKnAE++tXQrdPZyU2cHkuvg426snCjlpbogfmmlj8cGGb8EOZcdJv\n",
        "I3r+w2V+9bC2Z7O4OJhe2HlwM0N6F+KBnyJHsxbdP08OqZYzVMiDmg5Rfbkwf8W9\n",
        "arkt9+pAWSix0nkp7qNgD+qkjfrtOxIX//mFbIBWhhq1gSby5QKCAQEA63P0DsuC\n",
        "APhI0/GeSFJ8FXYtVFrX8/DJjOH441VEaQQMlAub6KnlhsOo0nS10A5GqV9/EeZ7\n",
        "ss2w22JwIh+Wk6PtxPU7lMEQRy1eV0GUrQdrE8StlLs36zszMswMafnm4yA4ki6g\n",
        "Lr3BR6Ps38TzLba6mctOFt9T8wV6+/YB2PFi3r5tmX0zYNQi6mbTFnlDv/dzaFOG\n",
        "fT823OuOzuwVvgu90651PutVfPrNhUTTykuGyDee5kkn21HQeguoLDWEIfeV+ujH\n",
        "l/AAT7rpNmxtSl0m+iwYsbKDbX28DCGnWXgeMuFgMUblRvKumChbno81JkJIOOwV\n",
        "+DcWryqTLp17VwKCAQEAx4XN5+PGMg9na7vZW6zU8r92RFKsjjhueygtpxdDUjdV\n",
        "MSYPu4mgO9ab62nf9LQJE2JCN6e8zHWEAooaIt83TzCa6SaYbTEnzin2M9gSYtW6\n",
        "MQ429zq49MOdZfwMfRgfnFAnA8KDIfYqqcPcmnQWHWhNGXyS3CccYw+2+gmRHLoM\n",
        "ohcoVZne6VuMqkEzf8SDaR8k9gwVjqxVqpQN8p81PE00a02k+QDwyNsrcnM19plB\n",
        "kntb9FLuqQf+lmDhe0/9fDqcjIEDz4eonLlFaTrFegGybTQcKD+3uyC0k9njUFwJ\n",
        "Y77I3kJiaoDuXXVxWETS3KvaE2rmjXAEcrN5rkfO5wKCAQEAl+41kQputBOCYwjp\n",
        "Ov/Gw86DB4irCuTYGYmDIaZWw3DycOFg1Gw1CJXerRbUbxGXNRnDFBjmvwUNVzMY\n",
        "6lv5vQEtn0cjECTYTSWQV7ugpVpBFPt3ip6YQbjsm52hcQzpmKuk9WcSw7Z8Lq8v\n",
        "XWFoDZp4pF7U39tx/0INDuK6ZHO2ecblUALDEXsxoJGDKmBLgGa7WJl1EgKlcz6o\n",
        "4wriKMTI0/wh+dy/SCtKTPGRvFqp+S4y4aRZDKOpY+d7uDM8NPLfG43zpS4f9VLF\n",
        "w/GJQFAFo66qrJdlSVS18BoTM59X1Tsq6AE4V2SnltWL8S+1ex+QHPLyZj2d7KAL\n",
        "YywJdwKCAQEApWUG3j6T0nWwfr82nGc2E5ChgluiTTb8Zr1Ustl25hWWWmq5yfV5\n",
        "TYFGuSyICTqg91+Rkr9Ko5aa+tvudI/jMpMRJ0rmOkXwQFfKjwmDnEid0wJ8kA8u\n",
        "uT/bH2qEE8LGmXZcESLSP3nnvdjt619l4bTPjNwWhccqIfgp7zW1BEI6LLfTqLon\n",
        "7fwFLDFmdni5ko/NvOUhjabQUNnwgfp2T+mUFYtEwWGFOItuha55wlUi5UG7ZVrG\n",
        "GnrVEWV4JReXAr83fMWKGiPToy92GZgtkUkM1rfGy5qePNIMvy903u2cnwHNU2lm\n",
        "WfFNJ04uykQrI+CVo1kPi5mbJlYe/VjrawKCAQEA5Pmjb8/MdAUEkb3zAD7GJIKC\n",
        "HnUAA4mwk8xVdsGN6xvUL8RYgi+VjSKvzNsUln5sPXdtZbP//gQOF7KgLPFFe+mf\n",
        "Xok7fGSTQ1DgVWEErFynAYxu+Uu4xtjRbPyCXjyoHianXkn3QDf1ggpF+y2R0Ivu\n",
        "oyxsDvMArFalbmK4q/+Q6/z/DtnirfjUnxiYEPEBZtP3Gz74KQK/AhForVlCiSz6\n",
        "MbDp30cxPy/8/pimJ9xUR6re9Xuw/EFWp0ifHXv6IGNOd8UQGejyI82KnJZPNTde\n",
        "tHO70d3zFdhrpJO63Elrw6c9bxeZrcJTT1e3wFpX2z1aE4dybdNqrI/IbzcdVA==\n",
        "-----END RSA PRIVATE KEY-----\n",
        "\"\"\")\n",
        "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "! chmod go-rwx /root/.ssh/id_rsa\n",
        "! git clone git@github.com:Tien-Cheng/dele-generative-adversarial-networks.git\n",
        "%cd /content/dele-generative-adversarial-networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRBkXblK-YpQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U torchmetrics[image] wandb torch-summary pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w4OzpB6-c_1"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw-0sgET-fKb"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zumKbcFW-cqB",
        "outputId": "c017a963-122d-4adf-de37-4f9bbb186895"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import wandb\n",
        "import torchvision.utils as vutils\n",
        "import gc\n",
        "\n",
        "from typing import *\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.optim import Adam\n",
        "from data.dataset import CIFAR10DataModule\n",
        "from torchvision import transforms as T\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelSummary, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from utils.DiffAugment_pytorch import (\n",
        "    DiffAugment,\n",
        ")  # Make use of the official implementation of DiffAugment\n",
        "from utils.visualize import visualize\n",
        "from utils.layers import (\n",
        "    ResidualBlockDiscriminator,\n",
        "    ResidualBlockGenerator,\n",
        "    NormalizeInverse,\n",
        "    ConditionalBatchNorm2d,\n",
        "    ResidualBlockDiscriminatorHead,\n",
        ")\n",
        "from utils.ema import EMA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0RQBSYpS_HQ"
      },
      "source": [
        "### Basic Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gLPRMOsgSW8w",
        "outputId": "cae5707b-9a4a-4e95-f7fa-397a39c719f6"
      },
      "outputs": [],
      "source": [
        "# @title Basic Hyperparameters { run: \"auto\" }\n",
        "DATA_DIR = \"./data\"  # @param {type:\"string\"}\n",
        "BATCH_SIZE = 50  # @param {type:\"integer\"}\n",
        "NUM_WORKERS = 2  # @param {type:\"integer\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu9T96d-_Rnf"
      },
      "source": [
        "## Data Ingestion and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q4fq4ltATFhN",
        "outputId": "a6183af8-1173-4ab6-8f84-884ed1dfbf5f"
      },
      "outputs": [],
      "source": [
        "preprocessing = [T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "basic_aug = [\n",
        "    T.RandomHorizontalFlip()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "P1YteEfJSKQY",
        "outputId": "f6c13f91-f7e7-4237-de35-de50e6c4c2fc"
      },
      "outputs": [],
      "source": [
        "dm = CIFAR10DataModule(\n",
        "    data_dir=DATA_DIR,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    transforms=preprocessing,\n",
        "    augments=basic_aug\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag08rZ3W_d3E"
      },
      "source": [
        "# Building a Conditional LSGAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf2aymldARgo"
      },
      "source": [
        "## Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iMQ65GSH_3sf"
      },
      "outputs": [],
      "source": [
        "class LSGANGenerator(nn.Module):\n",
        "    def __init__(\n",
        "        self, latent_dim: int = 100, num_filters: int = 64, num_classes: int = 10\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_filters = num_filters  # Base Number of Filters in Generator Blocks\n",
        "        self.num_classes = num_classes\n",
        "        self.label_embedding = nn.Embedding(num_classes, latent_dim)\n",
        "        self.latent = nn.Linear(latent_dim, latent_dim)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, num_filters * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(num_filters * 4, num_filters * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(num_filters * 2, num_filters, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(num_filters, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: list = None):\n",
        "        conditional_inputs = torch.mul(x, self.label_embedding(y))\n",
        "        conditional_inputs = self.latent(conditional_inputs)\n",
        "        conditional_inputs = conditional_inputs.view(\n",
        "            conditional_inputs.shape[0], self.latent_dim, 1, 1\n",
        "        )\n",
        "        return self.main(conditional_inputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCRwH4cAATql"
      },
      "source": [
        "## Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pj4rGgeiAVkX"
      },
      "outputs": [],
      "source": [
        "class LSGANDiscriminator(nn.Module):\n",
        "    def __init__(self, num_filters: int = 64, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.num_classes = num_classes\n",
        "        self.label_embedding = nn.Embedding(num_classes, 32 * 32)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, num_filters, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(num_filters, num_filters * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(num_filters * 2, num_filters * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(\n",
        "                num_filters * 4, 1, 4, 1, 0, bias=False\n",
        "            ),  # Apply a 4x4 Convolution to a 4x4 input, resulting in a 1x1 output\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: list = None):\n",
        "        labels = self.label_embedding(y)\n",
        "        labels = labels.view(labels.shape[0], 1, 32, 32)\n",
        "        conditional_inputs = torch.mul(x, labels)  # Concat as Extra Channel\n",
        "        return self.main(conditional_inputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRpJbKQRBDTY"
      },
      "source": [
        "## Conditional LSGAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C00_pmG1ENMo"
      },
      "outputs": [],
      "source": [
        "class ConditionalLSGAN(LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 100,\n",
        "        num_classes: int = 10,\n",
        "        g_lr: float = 0.0002,\n",
        "        d_lr: float = 0.0002,\n",
        "        adam_betas: Tuple[float, float] = (0.5, 0.999),\n",
        "        batch_size: int = 64,\n",
        "        validation_size: int = 10000,\n",
        "        d_steps: int = 1,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.g_lr = g_lr\n",
        "        self.d_lr = d_lr\n",
        "        self.betas = adam_betas\n",
        "        self.batch_size = batch_size\n",
        "        self.validation_size = validation_size  # For FID, minimum number of samples is 10K for accurate result\n",
        "        self.d_steps = d_steps  # Number of Discriminator steps per Generator Step\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.G = LSGANGenerator(\n",
        "            latent_dim=self.latent_dim,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        self.D = LSGANDiscriminator(num_classes=num_classes)\n",
        "\n",
        "        self.G.apply(self._weights_init)\n",
        "        self.D.apply(self._weights_init)\n",
        "\n",
        "        self.adversarial_loss = nn.MSELoss()  # Least Squares Loss\n",
        "\n",
        "        self.fid = FrechetInceptionDistance()\n",
        "        self.inception_score = InceptionScore()\n",
        "        self.unnormalize = NormalizeInverse((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find(\"Conv\") != -1:\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        elif classname.find(\"BatchNorm\") != -1:\n",
        "            torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        return self.G(z, labels)\n",
        "\n",
        "    # Alternating schedule for optimizer steps (i.e.: GANs)\n",
        "    def optimizer_step(\n",
        "        self,\n",
        "        epoch,\n",
        "        batch_idx,\n",
        "        optimizer,\n",
        "        optimizer_idx,\n",
        "        optimizer_closure,\n",
        "        on_tpu,\n",
        "        using_native_amp,\n",
        "        using_lbfgs,\n",
        "    ):\n",
        "        # update discriminator opt every step\n",
        "        if optimizer_idx == 1:\n",
        "            optimizer.step(closure=optimizer_closure)\n",
        "\n",
        "        # update generator opt every 4 steps\n",
        "        if optimizer_idx == 0:\n",
        "            if (batch_idx + 1) % self.d_steps == 0:\n",
        "                optimizer.step(closure=optimizer_closure)\n",
        "            else:\n",
        "                # call the closure by itself to run `training_step` + `backward` without an optimizer step\n",
        "                optimizer_closure()\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        imgs, labels = batch  # Get real images and corresponding labels\n",
        "\n",
        "        # Generate Noise Vector z\n",
        "        z = torch.randn(imgs.shape[0], self.latent_dim)\n",
        "        z = z.type_as(imgs)  # Ensure z runs on the same device as the images\n",
        "        self.fake_labels = torch.LongTensor(\n",
        "            torch.randint(0, self.num_classes, (imgs.shape[0],))\n",
        "        ).to(self.device)\n",
        "        # Train Generator\n",
        "        if optimizer_idx == 0:\n",
        "            # Generate Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "\n",
        "            # Classify Generated Images with Discriminator\n",
        "            fake_preds = torch.squeeze(self.D(self.fakes, self.fake_labels))\n",
        "\n",
        "            # We want to penalize the Generator if the Discriminator predicts it as fake\n",
        "            # Hence, set the target as a 1's vector\n",
        "            target = torch.ones(imgs.shape[0]).type_as(imgs)\n",
        "\n",
        "            g_loss = self.adversarial_loss(fake_preds, target)\n",
        "\n",
        "            self.log(\n",
        "                \"train_gen_loss\",\n",
        "                g_loss,\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )  # Log Generator Loss\n",
        "            tqdm_dict = {\n",
        "                \"g_loss\": g_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "        # Train Discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Train on Real Data\n",
        "            real_preds = torch.squeeze(self.D(imgs, labels))\n",
        "            target = torch.ones(imgs.shape[0]).type_as(imgs)\n",
        "            d_real_loss = self.adversarial_loss(real_preds, target)\n",
        "\n",
        "            # Train on Generated Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "            target = torch.zeros(imgs.shape[0]).type_as(imgs)\n",
        "            fake_preds = torch.squeeze(self.D(self.fakes, self.fake_labels))\n",
        "            d_fake_loss = self.adversarial_loss(fake_preds, target)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "            self.log(\n",
        "                \"train_discriminator_loss\",\n",
        "                d_loss,\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )\n",
        "            tqdm_dict = {\n",
        "                \"d_loss\": d_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        # Log Sampled Images\n",
        "        sample_imgs = self.unnormalize(self.fakes[:64]).cpu().detach()\n",
        "        sample_labels = self.fake_labels[:64].cpu().detach()\n",
        "        num_rows = int(np.floor(np.sqrt(len(sample_imgs))))\n",
        "        fig = visualize(sample_imgs, sample_labels, grid_shape=(num_rows, num_rows))\n",
        "        self.logger.log_image(key=\"generated_images\", images=[fig])\n",
        "        plt.close(fig)\n",
        "        del sample_imgs\n",
        "        del sample_labels\n",
        "        del fig\n",
        "        gc.collect()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Update FID for real Data\n",
        "        \"\"\"\n",
        "        real, _ = batch\n",
        "        # Calculate Metrics for Real Data\n",
        "        torch.cuda.empty_cache()\n",
        "        real = self.unnormalize(real)\n",
        "        real = (real * 255).type(torch.uint8).to(self.device)\n",
        "        self.fid.update(\n",
        "            real, real=True\n",
        "        )  # Only log on the end of the epoch as it does not make sense\n",
        "        validation_size = self.validation_size // self.batch_size\n",
        "        validation_z = torch.randn(validation_size, self.latent_dim)\n",
        "        validation_labels = torch.LongTensor(\n",
        "            torch.randint(0, self.num_classes, (validation_size,))\n",
        "        ).to(self.device)\n",
        "        # Generate Images. A minimum of 10K is recommended for accurate FID\n",
        "        validation_z = validation_z.type_as(\n",
        "            self.G.latent.weight\n",
        "        )  # Ensure z runs on the same device as the images\n",
        "        fakes = self.forward(\n",
        "            validation_z, validation_labels\n",
        "        )  # Display only the first 9 images\n",
        "        fakes = (self.unnormalize(fakes) * 255).type(torch.uint8).to(self.device)\n",
        "        self.inception_score.update(fakes)\n",
        "        self.fid.update(\n",
        "            fakes,\n",
        "            real=False,\n",
        "        )\n",
        "       \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log(\n",
        "            \"IS\",\n",
        "            self.inception_score.compute()[0],  # Compute Mean IS\n",
        "            prog_bar=True,\n",
        "        )\n",
        "        self.log(\"FID\", self.fid, prog_bar=True)\n",
        "        self.fid.reset()\n",
        "        self.inception_score.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Define the optimizers and schedulers for PyTorch Lightning\n",
        "\n",
        "        :return: A tuple of two lists - a list of optimizers and a list of learning rate schedulers\n",
        "        :rtype: Tuple[List, List]\n",
        "        \"\"\"\n",
        "        opt_G = Adam(\n",
        "            self.G.parameters(), lr=self.g_lr, betas=self.betas\n",
        "        )  # optimizer_idx = 0\n",
        "        opt_D = Adam(\n",
        "            self.D.parameters(), lr=self.d_lr, betas=self.betas\n",
        "        )  # optimizer_idx = 1\n",
        "        return [opt_G, opt_D], []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9LXzAqIAbY0"
      },
      "source": [
        "## Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtiencheng\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n",
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FrechetInceptionDistance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "# seed_everything(42)\n",
        "# wandb_logger = WandbLogger(project=\"DELE_CA2_GAN\", log_model=\"all\")\n",
        "# model = ConditionalLSGAN(g_lr=0.0001, d_lr=0.0003, batch_size=BATCH_SIZE)\n",
        "# trainer = Trainer(\n",
        "#     check_val_every_n_epoch=5,\n",
        "#     logger=wandb_logger,\n",
        "#     max_epochs=1000,\n",
        "#     callbacks=[\n",
        "#         ModelCheckpoint(monitor=\"FID\", mode=\"min\", every_n_epochs=1),\n",
        "#         ModelSummary(3),\n",
        "#     ],\n",
        "#     gpus=1,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "  rank_zero_warn(\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | G                 | LSGANGenerator     | 3.7 M \n",
            "1 | G.label_embedding | Embedding          | 100   \n",
            "2 | G.main            | Sequential         | 3.7 M \n",
            "3 | D                 | LSGANDiscriminator | 2.8 M \n",
            "4 | D.label_embedding | Embedding          | 100   \n",
            "5 | D.main            | Sequential         | 2.8 M \n",
            "6 | adversarial_loss  | MSELoss            | 0     \n",
            "7 | fid               | FID                | 23.9 M\n",
            "8 | fid.inception     | NoTrainInceptionV3 | 23.9 M\n",
            "9 | unnormalize       | NormalizeInverse   | 0     \n",
            "---------------------------------------------------------\n",
            "6.4 M     Trainable params\n",
            "23.9 M    Non-trainable params\n",
            "30.3 M    Total params\n",
            "121.101   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a980d1c7c03448b1b36ff11ee8235ce6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tiencheng/GitHub/dele-generative-adversarial-networks/env/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ],
      "source": [
        "# trainer.fit(model, dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Improving the Generator and Discriminator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Improving the Generator\n",
        "\n",
        "Introducing\n",
        "\n",
        "- Spectral Normalization\n",
        "- Upsampling instead of Transposed Convolutions\n",
        "- Residual Connections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNetGenerator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 128,\n",
        "        num_filters: int = 256,\n",
        "        num_classes: int = 10,\n",
        "        activation: callable = F.relu,\n",
        "        use_spectral_norm: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_filters = num_filters\n",
        "        self.num_classes = num_classes\n",
        "        self.use_spectral_norm = use_spectral_norm\n",
        "        self.embed = spectral_norm(nn.Embedding(num_classes, num_filters))\n",
        "        self.latent = nn.Linear(latent_dim, num_filters * 4 * 4)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                ResidualBlockGenerator(\n",
        "                    in_ch=num_filters,\n",
        "                    out_ch=num_filters,\n",
        "                    activation=activation,\n",
        "                    upsample=True,\n",
        "                    num_classes=num_classes,\n",
        "                    use_spectral_norm=use_spectral_norm,\n",
        "                )\n",
        "                for _ in range(3)  # Input: 4x4 | -> 8x8 -> 16x16 -> 32x32\n",
        "            ]\n",
        "        )\n",
        "        self.output = [\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters, 3, kernel_size=3, padding=1, stride=1),\n",
        "            nn.Tanh(),\n",
        "        ]\n",
        "        if use_spectral_norm:\n",
        "            self.output[2] = spectral_norm(self.output[2])\n",
        "\n",
        "        self.output = nn.Sequential(*self.output)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        y_embed = self.embed(y)\n",
        "        h = self.latent(x)\n",
        "        h = h.view(h.shape[0], self.num_filters, 4, 4)\n",
        "        for block in self.blocks:\n",
        "            h = block(h, y_embed)\n",
        "        return self.output(h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNetDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_filters: int = 128,\n",
        "        num_classes: int = 10,\n",
        "        activation: callable = F.relu,\n",
        "    ):\n",
        "        \"\"\"Implementation inspired by Projection Discriminator: https://github.com/pfnet-research/sngan_projection/blob/master/dis_models/snresnet_32.py\n",
        "\n",
        "        :param num_filters: [description], defaults to 128\n",
        "        :type num_filters: int, optional\n",
        "        :param num_classes: [description], defaults to 10\n",
        "        :type num_classes: int, optional\n",
        "        :param activation: [description], defaults to F.relu\n",
        "        :type activation: callable, optional\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.num_classes = num_classes\n",
        "        self.activation = activation\n",
        "        self.blocks = nn.Sequential(\n",
        "            ResidualBlockDiscriminatorHead(3, num_filters, activation=activation),\n",
        "            ResidualBlockDiscriminator(\n",
        "                num_filters, num_filters, activation=activation, downsample=True\n",
        "            ),\n",
        "            ResidualBlockDiscriminator(\n",
        "                num_filters, num_filters, activation=activation, downsample=False\n",
        "            ),\n",
        "            ResidualBlockDiscriminator(\n",
        "                num_filters, num_filters, activation=activation, downsample=False\n",
        "            ),\n",
        "        )\n",
        "        self.classifier = spectral_norm(nn.Linear(num_filters, 1, bias=False))\n",
        "        self.embed = spectral_norm(nn.Embedding(num_classes, num_filters))\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.blocks(x)\n",
        "        h = self.activation(h)\n",
        "        h = h.mean([2, 3])  # Global Avg Pooling\n",
        "        out = self.classifier(h)\n",
        "        out = out + torch.sum(self.embed(y) * h, axis=1, keepdims=True)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introducing Differentiable Augmentations to Reduce Overfitting of Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalLSGAN_Aug(ConditionalLSGAN):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 128,\n",
        "        num_classes: int = 10,\n",
        "        g_lr: float = 0.0002,\n",
        "        d_lr: float = 0.0002,\n",
        "        adam_betas: Tuple[float, float] = (0.0, 0.9),\n",
        "        batch_size: int = 64,\n",
        "        validation_size: int = 10000,\n",
        "        policy: str = \"color,translation,cutout\",\n",
        "        d_steps: int = 1,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            latent_dim,\n",
        "            num_classes,\n",
        "            g_lr,\n",
        "            d_lr,\n",
        "            adam_betas,\n",
        "            batch_size,\n",
        "            validation_size,\n",
        "            d_steps ** kwargs,\n",
        "        )\n",
        "\n",
        "        self.policy = policy\n",
        "        self.save_hyperparameters(\"policy\")\n",
        "\n",
        "        self.G = ResNetGenerator(\n",
        "            latent_dim=self.latent_dim,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        self.D = ResNetDiscriminator(num_classes=num_classes)\n",
        "\n",
        "        self.G.apply(self._weights_init)\n",
        "        self.D.apply(self._weights_init)\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        if (\n",
        "            isinstance(m, nn.Linear)\n",
        "            or isinstance(m, nn.Conv2d)\n",
        "            or isinstance(m, nn.Embedding)\n",
        "        ):\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        imgs, labels = batch  # Get real images and corresponding labels\n",
        "        imgs = DiffAugment(imgs, policy=self.policy)\n",
        "        # Generate Noise Vector z\n",
        "        z = torch.randn(imgs.shape[0], self.latent_dim)\n",
        "        z = z.type_as(imgs)  # Ensure z runs on the same device as the images\n",
        "        self.fake_labels = torch.LongTensor(\n",
        "            torch.randint(0, self.num_classes, (imgs.shape[0],))\n",
        "        ).to(self.device)\n",
        "        # Train Generator\n",
        "        if optimizer_idx == 0:\n",
        "            # Generate Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "\n",
        "            # Classify Generated Images with Discriminator\n",
        "            fake_preds = torch.squeeze(\n",
        "                self.D(DiffAugment(self.fakes, policy=self.policy), self.fake_labels)\n",
        "            )\n",
        "\n",
        "            # We want to penalize the Generator if the Discriminator predicts it as fake\n",
        "            # Hence, set the target as a 1's vector\n",
        "            target = torch.ones(imgs.shape[0]).type_as(imgs)\n",
        "\n",
        "            g_loss = self.adversarial_loss(fake_preds, target)\n",
        "\n",
        "            self.log(\n",
        "                \"train_gen_loss\",\n",
        "                g_loss.detach(),\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )  # Log Generator Loss\n",
        "            tqdm_dict = {\n",
        "                \"g_loss\": g_loss.detach(),\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "        # Train Discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Train on Real Data\n",
        "            real_preds = torch.squeeze(self.D(imgs, labels))\n",
        "            target = torch.ones(imgs.shape[0]).type_as(imgs)\n",
        "            d_real_loss = self.adversarial_loss(real_preds, target)\n",
        "\n",
        "            # Train on Generated Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "            target = torch.zeros(imgs.shape[0]).type_as(imgs)\n",
        "            fake_preds = torch.squeeze(\n",
        "                self.D(DiffAugment(self.fakes, policy=self.policy), self.fake_labels)\n",
        "            )\n",
        "            d_fake_loss = self.adversarial_loss(fake_preds, target)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "            self.log(\n",
        "                \"train_discriminator_loss\",\n",
        "                d_loss.detach(),\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )\n",
        "            tqdm_dict = {\n",
        "                \"d_loss\": d_loss.detach(),\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- DiffAugment was too powerful, causing model to collapse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# seed_everything(42)\n",
        "# wandb_logger = WandbLogger(project=\"DELE_CA2_GAN\", log_model=\"all\")\n",
        "# model = ConditionalLSGAN_Aug(g_lr=0.0001, d_lr=0.0004, batch_size=BATCH_SIZE)\n",
        "# trainer = Trainer(\n",
        "#     check_val_every_n_epoch=5,\n",
        "#     logger=wandb_logger,\n",
        "#     max_epochs=1000,\n",
        "#     callbacks=[\n",
        "#         # ModelCheckpoint(monitor=\"FID\", mode=\"min\", every_n_epochs=1),\n",
        "#         ModelSummary(3),\n",
        "#     ],\n",
        "#     gpus=1,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer.fit(model, dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hinge Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalSNGAN_Aug(ConditionalLSGAN):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 128,\n",
        "        num_classes: int = 10,\n",
        "        g_lr: float = 0.0002,\n",
        "        d_lr: float = 0.0002,\n",
        "        adam_betas: Tuple[float, float] = (0.0, 0.9),\n",
        "        batch_size: int = 64,\n",
        "        validation_size: int = 10000,\n",
        "        policy: str = \"color,translation,cutout\",\n",
        "        d_steps: int = 1,\n",
        "        w_init_policy: str = \"ortho\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            latent_dim,\n",
        "            num_classes,\n",
        "            g_lr,\n",
        "            d_lr,\n",
        "            adam_betas,\n",
        "            batch_size,\n",
        "            validation_size,\n",
        "            d_steps,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.policy = policy\n",
        "        self.w_init_policy = w_init_policy\n",
        "\n",
        "        self.save_hyperparameters(\"policy\", \"w_init_policy\")\n",
        "\n",
        "        self.G = ResNetGenerator(\n",
        "            latent_dim=self.latent_dim,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        self.D = ResNetDiscriminator(num_classes=num_classes)\n",
        "        if w_init_policy == \"normal\":\n",
        "            init_func = self._normal_weights_init\n",
        "        elif w_init_policy == \"ortho\":\n",
        "            init_func = self._ortho_weights_init\n",
        "        else:\n",
        "            raise ValueError(\"Unknown Weight Init Policy\")\n",
        "        self.G.apply(init_func)\n",
        "        self.D.apply(init_func)\n",
        "\n",
        "    @staticmethod\n",
        "    def _normal_weights_init(m):\n",
        "        if (\n",
        "            isinstance(m, nn.Linear)\n",
        "            or isinstance(m, nn.Conv2d)\n",
        "            or isinstance(m, nn.Embedding)\n",
        "        ):\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "    @staticmethod\n",
        "    def _ortho_weights_init(m):\n",
        "        if (\n",
        "            isinstance(m, nn.Linear)\n",
        "            or isinstance(m, nn.Conv2d)\n",
        "            or isinstance(m, nn.Embedding)\n",
        "        ):\n",
        "            torch.nn.init.orthogonal_(m.weight)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        imgs, labels = batch  # Get real images and corresponding labels\n",
        "        imgs = DiffAugment(imgs, policy=self.policy)\n",
        "        # Generate Noise Vector z\n",
        "        z = torch.randn(imgs.shape[0], self.latent_dim)\n",
        "        z = z.type_as(imgs)  # Ensure z runs on the same device as the images\n",
        "        self.fake_labels = torch.LongTensor(\n",
        "            torch.randint(0, self.num_classes, (imgs.shape[0],))\n",
        "        ).to(self.device)\n",
        "        # Train Generator\n",
        "        if optimizer_idx == 0:\n",
        "            # Generate Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "\n",
        "            # Classify Generated Images with Discriminator\n",
        "            fake_preds = torch.squeeze(\n",
        "                self.D(DiffAugment(self.fakes, policy=self.policy), self.fake_labels)\n",
        "            )\n",
        "\n",
        "            g_loss = -fake_preds.mean()\n",
        "\n",
        "            self.log(\n",
        "                \"train_gen_loss\",\n",
        "                g_loss,\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )  # Log Generator Loss\n",
        "            tqdm_dict = {\n",
        "                \"g_loss\": g_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n",
        "\n",
        "        # Train Discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Train on Real Data\n",
        "            real_preds = torch.squeeze(self.D(imgs, labels))\n",
        "            d_real_loss = F.relu(1.0 - real_preds).mean()\n",
        "\n",
        "            # Train on Generated Images\n",
        "            self.fakes = self.forward(z, self.fake_labels)\n",
        "            fake_preds = torch.squeeze(\n",
        "                self.D(DiffAugment(self.fakes, policy=self.policy), self.fake_labels)\n",
        "            )\n",
        "            d_fake_loss = F.relu(1.0 + fake_preds).mean()\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "            self.log(\n",
        "                \"train_discriminator_loss\",\n",
        "                d_loss,\n",
        "                on_epoch=True,\n",
        "                on_step=False,\n",
        "                prog_bar=True,\n",
        "            )\n",
        "            tqdm_dict = {\n",
        "                \"d_loss\": d_loss,\n",
        "            }\n",
        "            output = OrderedDict(\n",
        "                {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
        "            )\n",
        "            return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# seed_everything(42)\n",
        "# wandb_logger = WandbLogger(project=\"DELE_CA2_GAN\", log_model=\"all\")\n",
        "# model = ConditionalSNGAN_Aug(\n",
        "#     g_lr=0.0001, d_lr=0.0004, batch_size=BATCH_SIZE, policy=\"\", adam_betas=(0, 0.999)\n",
        "# )\n",
        "# trainer = Trainer(\n",
        "#     check_val_every_n_epoch=5,\n",
        "#     logger=wandb_logger,\n",
        "#     max_epochs=1000,\n",
        "#     callbacks=[\n",
        "#         # ModelCheckpoint(monitor=\"FID\", mode=\"min\", every_n_epochs=1),\n",
        "#         ModelSummary(3),\n",
        "#     ],\n",
        "#     gpus=1,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer.fit(model, dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exponential Moving Average of Model Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_everything(42)\n",
        "wandb_logger = WandbLogger(project=\"DELE_CA2_GAN\", log_model=\"all\")\n",
        "model = ConditionalSNGAN_Aug(\n",
        "    g_lr=0.0002,\n",
        "    d_lr=0.0002,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    policy=\"translation\",\n",
        "    adam_betas=(0.0, 0.999),\n",
        "    d_steps=4,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    check_val_every_n_epoch=5,\n",
        "    logger=wandb_logger,\n",
        "    max_epochs=1000,\n",
        "    callbacks=[\n",
        "        # ModelCheckpoint(monitor=\"FID\", mode=\"min\", every_n_epochs=1),\n",
        "        ModelSummary(3),\n",
        "        EMA(ema_device=\"cuda\"),\n",
        "    ],\n",
        "    gpus=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.fit(model, dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOI56mbxgkF+EXTRTq++yJk",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "DELE CA2 Part I - Controllable & Conditional GANS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
